{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “What-If” Exploratory Prompting\n",
    "\n",
    "“What-If” Exploratory Prompting pushes the model to examine hypothetical scenarios, stress-testing the robustness of the core idea and uncovering hidden requirements or edge cases. It is particularly useful in requirement analysis and risk assessment.\n",
    "\n",
    "## Core Idea\n",
    "1.\t**Hypothetical Changes:** Ask the model, “What if X changes or fails?”\n",
    "2.\t**Branching Scenarios:** Each scenario leads to new requirements or design constraints.\n",
    "3.\t**Risk Mitigation:** Surfaces potential pitfalls early in the design process.\n",
    "\n",
    "## References\n",
    "* https://www.analyticsvidhya.com/blog/2024/10/17-prompting-techniques-to-supercharge-your-llms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': \"\\nYou are a requirements analyst. \\n1) For each 'What-If' scenario provided, outline the new or modified requirements.\\n2) Highlight potential constraints or design considerations that might arise.\\nScenario: \\nWe are developing a smart thermostat that adapts to real-time energy prices \\nand occupant comfort preferences. Explore 'What-If' scenarios:\\n- Sudden surge in energy prices\\n- Power outages\\n- Multi-zone heating vs. single-zone\\n\\n\", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 120, 'num_predict': 200}}\n",
      "As a requirements analyst, I'll break down the \"What-If\" scenarios and outline potential design considerations for the smart thermostat:\n",
      "\n",
      "**Scenario 1: Sudden Surge in Energy Prices**\n",
      "\n",
      "* **Requirements Analysis**:\n",
      "\t+ The thermostat should be able to detect sudden changes in energy prices and adjust heating/cooling settings accordingly.\n",
      "\t+ The system should prioritize energy efficiency, reducing waste and unnecessary consumption.\n",
      "\t+ Consider implementing a \"price adjustment\" feature that allows users to set their preferred price threshold for energy savings.\n",
      "* **Design Considerations**:\n",
      "\t+ Integrate with an energy market platform or API to fetch real-time energy prices and adjust pricing accordingly.\n",
      "\t+ Implement a machine learning algorithm to analyze user behavior and optimize energy consumption.\n",
      "\n",
      "What would you like to do next?\n",
      "\n",
      "A) Explore more design considerations\n",
      "B) Discuss the technical feasibility of implementing the features mentioned\n",
      "C) Brainstorm alternative approaches for optimizing energy consumption\n",
      "\n",
      "Please select an option.\n",
      "Time taken: 11.235s\n"
     ]
    }
   ],
   "source": [
    "# what_if_exploratory.ipynb\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "MESSAGE = \"\"\"\n",
    "We are developing a smart thermostat that adapts to real-time energy prices \n",
    "and occupant comfort preferences. Explore 'What-If' scenarios:\n",
    "- Sudden surge in energy prices\n",
    "- Power outages\n",
    "- Multi-zone heating vs. single-zone\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = f\"\"\"\n",
    "You are a requirements analyst. \n",
    "1) For each 'What-If' scenario provided, outline the new or modified requirements.\n",
    "2) Highlight potential constraints or design considerations that might arise.\n",
    "Scenario: {MESSAGE}\n",
    "\"\"\"\n",
    "\n",
    "payload = create_payload(\n",
    "    target=\"ollama\",\n",
    "    model=\"llama3.2:latest\",\n",
    "    prompt=PROMPT,\n",
    "    temperature=1.0,\n",
    "    num_ctx=120,\n",
    "    num_predict=200\n",
    ")\n",
    "\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: \n",
    "    print(f'Time taken: {time}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
